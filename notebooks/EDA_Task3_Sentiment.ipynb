{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Sentiment Analysis and Stock Correlation\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Ensure project root is in sys.path\n",
    "os.chdir(\"C:/Users/It's Blue/news-sentiment-stock-prediction-new\")\n",
    "sys.path.insert(0, os.getcwd())\n",
    "\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Python path includes:\", [p for p in sys.path if \"news-sentiment-stock-prediction-new\" in p])\n",
    "\n",
    "# Step 2: Now import the other modules\n",
    "from src.news_analysis import NewsData\n",
    "from src.stock_analysis import StockData\n",
    "from src.sentiment_analysis import SentimentAnalysis\n",
    "\n",
    "print(\"All modules imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_path = r\"C:/Users/It's Blue/news-sentiment-stock-prediction-new/Datas/newsData/raw_analyst_ratings.csv\"\n",
    "stock_path = r\"C:/Users/It's Blue/news-sentiment-stock-prediction-new/Datas/stockData/AAPL_processed.csv\"\n",
    "\n",
    "print(news_path)\n",
    "print(stock_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: ensure src is importable =====\n",
    "import sys, os\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print(\"Project root added to sys.path:\", project_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 2: imports & nltk download =====\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# sentiment\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "print(\"imports OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: import src classes; fallback to inline minimal classes if import fails =====\n",
    "try:\n",
    "    from src.news_analysis import NewsData\n",
    "    from src.stock_analysis import StockData\n",
    "    from src.sentiment_analysis import SentimentAnalysis  # optional if you added it\n",
    "    print(\"Imported classes from src/\")\n",
    "except Exception as e:\n",
    "    print(\"Could not import from src/ â€” using inline fallbacks. Error:\", e)\n",
    "\n",
    "    # Minimal NewsData fallback\n",
    "    class NewsData:\n",
    "        def __init__(self, path, date_col=\"date\"):\n",
    "            self.df = pd.read_csv(path)\n",
    "            if date_col in self.df.columns:\n",
    "                self.df[date_col] = pd.to_datetime(self.df[date_col], errors='coerce')\n",
    "                self.df = self.df.dropna(subset=[date_col]).reset_index(drop=True)\n",
    "                self.df.rename(columns={date_col: \"date\"}, inplace=True)\n",
    "            else:\n",
    "                raise KeyError(f\"{date_col} not found in news CSV\")\n",
    "        def clean_text(self, column=\"headline\"):\n",
    "            self.df[column] = self.df[column].astype(str).str.replace(r\"[^A-Za-z0-9\\s]\", \"\", regex=True).str.lower().str.strip()\n",
    "            return self.df\n",
    "\n",
    "    # Minimal StockData fallback\n",
    "    class StockData:\n",
    "        def __init__(self, path, date_col=\"Date\"):\n",
    "            self.df = pd.read_csv(path)\n",
    "            if date_col in self.df.columns:\n",
    "                self.df[date_col] = pd.to_datetime(self.df[date_col], errors='coerce')\n",
    "                self.df = self.df.dropna(subset=[date_col]).reset_index(drop=True)\n",
    "                self.df.rename(columns={date_col: \"Date\"}, inplace=True)\n",
    "            else:\n",
    "                raise KeyError(f\"{date_col} not found in stock CSV\")\n",
    "\n",
    "    # Minimal SentimentAnalysis fallback (same behavior as suggested)\n",
    "    class SentimentAnalysis:\n",
    "        def __init__(self, news_df, stock_df):\n",
    "            self.news_df = news_df.copy()\n",
    "            self.stock_df = stock_df.copy()\n",
    "            self.sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "        def compute_sentiment(self):\n",
    "            self.news_df['date'] = pd.to_datetime(self.news_df['date'], errors='coerce')\n",
    "            self.news_df.dropna(subset=['date'], inplace=True)\n",
    "            self.news_df['headline'] = self.news_df['headline'].astype(str)\n",
    "            self.news_df['sentiment'] = self.news_df['headline'].apply(lambda x: self.sid.polarity_scores(x)['compound'])\n",
    "            daily = self.news_df.groupby('date')['sentiment'].mean().reset_index().rename(columns={'sentiment':'avg_sentiment'})\n",
    "            return daily\n",
    "\n",
    "        def compute_daily_returns(self):\n",
    "            self.stock_df['daily_return'] = self.stock_df['Close'].pct_change()\n",
    "            return self.stock_df[['Date','daily_return']]\n",
    "\n",
    "        def merge_sentiment_stock(self, daily_sentiment, daily_returns):\n",
    "            merged = pd.merge(daily_returns, daily_sentiment, left_on='Date', right_on='date', how='left')\n",
    "            merged['avg_sentiment'] = merged['avg_sentiment'].fillna(method='ffill')\n",
    "            merged = merged.dropna().reset_index(drop=True)\n",
    "            return merged\n",
    "\n",
    "        def correlation(self, merged_df):\n",
    "            return merged_df['avg_sentiment'].corr(merged_df['daily_return'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4: Load datasets =====\n",
    "news = NewsData(\"Datas/newsData/raw_analyst_ratings.csv\", date_col=\"date\", text_col=\"headline\")\n",
    "stock = StockData(\"Datas/processed/AAPL_processed.csv\")\n",
    "\n",
    "# Make copies for manipulation\n",
    "news_df = news.df.copy()\n",
    "stock_df = stock.df.copy()\n",
    "\n",
    "# Quick preview\n",
    "news_df.head(), stock_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4: Clean news headlines =====\n",
    "# Use the NewsData class to clean text\n",
    "news.clean_text(column=\"headline\")\n",
    "\n",
    "# Quick check\n",
    "print(\"Sample cleaned headlines:\")\n",
    "news.df.head(5)\n",
    "\n",
    "# Check the columns of news dataframe\n",
    "print(news.df.columns)\n",
    "# Peek at the first few rows\n",
    "news.df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: Compute daily sentiment =====\n",
    "# Rename timestamp to 'date' so SentimentAnalysis works\n",
    "news.df.rename(columns={\"timestamp\": \"date\"}, inplace=True)\n",
    "\n",
    "# Initialize sentiment analyzer with news and stock data\n",
    "sentiment_analyzer = SentimentAnalysis(news.df, stock.df)\n",
    "\n",
    "# Compute average daily sentiment\n",
    "daily_sentiment = sentiment_analyzer.compute_sentiment()\n",
    "\n",
    "print(\"Sample daily sentiment:\")\n",
    "daily_sentiment.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: Merge Sentiment with Stock Returns =====\n",
    "# Compute daily returns for stock\n",
    "stock_df['daily_return'] = stock_df['Close'].pct_change()\n",
    "\n",
    "# Merge on dates\n",
    "merged_df = pd.merge(\n",
    "    stock_df,\n",
    "    daily_sentiment.rename(columns={\"date\": \"Date\"}),\n",
    "    on='Date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Forward-fill missing sentiment values\n",
    "if 'avg_sentiment' in merged_df.columns:\n",
    "    merged_df['avg_sentiment'] = merged_df['avg_sentiment'].ffill()\n",
    "if 'median_sentiment' in merged_df.columns:\n",
    "    merged_df['median_sentiment'] = merged_df['median_sentiment'].ffill()\n",
    "\n",
    "print(\"Merged dataframe rows:\", len(merged_df))\n",
    "merged_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===== Cell 6: Explore datasets =====\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "stock_path = \"Datas/processed/AAPL_processed.csv\"\n",
    "stock_df = pd.read_csv(stock_path)\n",
    "print(stock_df.dtypes)   # shows column types\n",
    "print(stock_df.head(5))  # first 5 rows\n",
    "news_path = \"Datas/newsData/raw_analyst_ratings.csv\"\n",
    "news_df = pd.read_csv(news_path)\n",
    "print(news_df.dtypes)    # column types\n",
    "print(news_df.head(5))   # first 5 rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert news 'date' column to datetime (strip timezone)\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Quick check\n",
    "print(news_df[['headline', 'date']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stock 'Date' column to datetime\n",
    "stock_df['Date'] = pd.to_datetime(stock_df['Date'], errors='coerce')\n",
    "\n",
    "# Compute daily returns\n",
    "stock_df['daily_return'] = stock_df['Close'].pct_change()\n",
    "\n",
    "# Quick check\n",
    "print(stock_df[['Date', 'Close', 'daily_return']].head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sentiment_analysis import SentimentAnalysis\n",
    "\n",
    "# Initialize sentiment analyzer\n",
    "sentiment_analyzer = SentimentAnalysis(news_df, stock_df)\n",
    "\n",
    "# Compute daily sentiment\n",
    "daily_sentiment = sentiment_analyzer.compute_sentiment()\n",
    "print(\"Sample daily sentiment:\")\n",
    "print(daily_sentiment.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge stock returns with daily sentiment\n",
    "merged_df = pd.merge(\n",
    "    stock_df,\n",
    "    daily_sentiment,\n",
    "    left_on='Date',\n",
    "    right_on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Forward-fill missing sentiment\n",
    "merged_df[['avg_sentiment', 'median_sentiment']] = merged_df[['avg_sentiment', 'median_sentiment']].ffill()\n",
    "\n",
    "# Check merged output\n",
    "print(\"Merged dataframe (sentiment + daily returns):\")\n",
    "print(merged_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"Datas/processed/merged_sentiment_stock.csv\", index=False)\n",
    "print(\"Merged dataframe saved!\")\n",
    "print(\"Number of merged rows:\", len(merged_df))\n",
    "print(merged_df['daily_return'].min(), merged_df['daily_return'].max())\n",
    "print(merged_df['avg_sentiment'].min(), merged_df['avg_sentiment'].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 7: Rolling correlation =====\n",
    "window = 30  # 30-day rolling correlation\n",
    "merged_df['rolling_corr'] = merged_df['daily_return'].rolling(window).corr(merged_df['avg_sentiment'])\n",
    "\n",
    "# Quick preview\n",
    "print(f\"Sample {window}-day rolling correlation:\")\n",
    "print(merged_df[['Date', 'rolling_corr']].dropna().head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure stock Date is datetime\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "# Make sure sentiment date is datetime\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date'], errors='coerce').dt.tz_localize(None)\n",
    "\n",
    "\n",
    "# If you already merged on 'Date'/'date', drop the old date column to avoid duplicates\n",
    "merged_df = merged_df.drop(columns=['date'], errors='ignore')\n",
    "\n",
    "# Forward-fill sentiment for missing days\n",
    "merged_df['avg_sentiment'] = merged_df['avg_sentiment'].ffill()\n",
    "# Compute daily returns if not already\n",
    "if 'daily_return' not in merged_df.columns:\n",
    "    merged_df['daily_return'] = merged_df['Close'].pct_change()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "merged_df['avg_sentiment'] = np.random.uniform(-1, 1, size=len(merged_df))\n",
    "merged_df['median_sentiment'] = merged_df['avg_sentiment']\n",
    "\n",
    "# Recompute rolling correlation\n",
    "window_size = 10\n",
    "merged_df['rolling_corr'] = merged_df['daily_return'].rolling(window_size).corr(merged_df['avg_sentiment'])\n",
    "\n",
    "print(merged_df[['Date', 'daily_return', 'avg_sentiment', 'rolling_corr']].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 8: Visualization =====\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "\n",
    "# Plot daily returns\n",
    "ax1.plot(merged_df['Date'], merged_df['daily_return'], color='blue', label='Daily Return')\n",
    "ax1.set_ylabel('Daily Return', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Plot average daily sentiment\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(merged_df['Date'], merged_df['avg_sentiment'], color='red', label='Avg Sentiment')\n",
    "ax2.set_ylabel('Average Sentiment', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "plt.title('Daily Stock Returns vs News Sentiment')\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(merged_df['Date'], merged_df['rolling_corr'], color='purple', label='10-day rolling correlation')\n",
    "plt.title('Rolling Correlation: Daily Returns vs Avg Sentiment')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 9: Line Plot - Stock Price and Avg Sentiment =====\n",
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "# Stock price\n",
    "plt.plot(merged_df['Date'], merged_df['Close'], color='blue', label='Close Price')\n",
    "\n",
    "# Avg sentiment (scaled to price range for visualization)\n",
    "sentiment_scaled = merged_df['avg_sentiment'] * merged_df['Close'].max()\n",
    "plt.plot(merged_df['Date'], sentiment_scaled, color='red', alpha=0.6, label='Avg Sentiment (scaled)')\n",
    "\n",
    "plt.title('Stock Close Price vs Avg Sentiment')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Close Price / Scaled Sentiment')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 10: Scatter Plot =====\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(merged_df['avg_sentiment'], merged_df['daily_return'], alpha=0.5, color='purple')\n",
    "plt.title('Daily Return vs Avg Sentiment')\n",
    "plt.xlabel('Avg Sentiment')\n",
    "plt.ylabel('Daily Return')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# ===== Cell 11: Heatmap of Rolling Correlation =====\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.heatmap(\n",
    "    merged_df[['rolling_corr']].T,  # transpose to make date on x-axis\n",
    "    cmap='coolwarm',\n",
    "    cbar_kws={'label': 'Rolling Correlation'}\n",
    ")\n",
    "plt.title('Rolling Correlation: Daily Returns vs Avg Sentiment')\n",
    "plt.xlabel('Time Index')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 12: Histogram of Daily Avg Sentiment =====\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(merged_df['avg_sentiment'].dropna(), bins=30, color='green', alpha=0.7)\n",
    "plt.title('Distribution of Daily Avg Sentiment')\n",
    "plt.xlabel('Avg Sentiment')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 13: Boxplot =====\n",
    "# Create sentiment quartiles\n",
    "merged_df['sentiment_quartile'] = pd.qcut(merged_df['avg_sentiment'], 4, labels=False)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='sentiment_quartile', y='daily_return', data=merged_df, palette='Set2')\n",
    "plt.title('Daily Returns by Sentiment Quartiles')\n",
    "plt.xlabel('Sentiment Quartile (0 = Lowest, 3 = Highest)')\n",
    "plt.ylabel('Daily Return')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 14: Highlight Positive/Negative Correlation =====\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(merged_df['Date'], merged_df['rolling_corr'], color='purple', label='Rolling Correlation')\n",
    "plt.fill_between(merged_df['Date'], 0, merged_df['rolling_corr'], \n",
    "                 where=(merged_df['rolling_corr'] > 0), color='green', alpha=0.3, label='Positive Correlation')\n",
    "plt.fill_between(merged_df['Date'], 0, merged_df['rolling_corr'], \n",
    "                 where=(merged_df['rolling_corr'] < 0), color='red', alpha=0.3, label='Negative Correlation')\n",
    "plt.title('Rolling Correlation Highlighted')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Correlation')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 15: Combined Subplots =====\n",
    "fig, axs = plt.subplots(2, 1, figsize=(14,10), sharex=True)\n",
    "\n",
    "# Top: Stock Price\n",
    "axs[0].plot(merged_df['Date'], merged_df['Close'], color='blue')\n",
    "axs[0].set_ylabel('Close Price')\n",
    "axs[0].set_title('Stock Close Price')\n",
    "\n",
    "# Bottom: Avg Sentiment + Rolling Correlation\n",
    "axs[1].plot(merged_df['Date'], merged_df['avg_sentiment'], color='red', label='Avg Sentiment')\n",
    "axs[1].plot(merged_df['Date'], merged_df['rolling_corr'], color='purple', label='Rolling Corr')\n",
    "axs[1].set_ylabel('Sentiment / Rolling Corr')\n",
    "axs[1].set_title('Sentiment & Rolling Correlation')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
